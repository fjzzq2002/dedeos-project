{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['docs', 'configs'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# Downloaded from https://datasets.d2.mpi-inf.mpg.de/rakshith/a4nt_usenix/dataset/dataset_blog.json\n",
    "with open(\"blog.json\", \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rawtext', 'author', 'gender', 'age', 'work', 'tokens', 'actage', 'split', 'attrib'])\n",
      "defaultdict(<class 'int'>, {'male': 9812, 'female': 9865})\n"
     ]
    }
   ],
   "source": [
    "docs = json_data['docs']\n",
    "sample = docs[1113]\n",
    "print(sample.keys())\n",
    "from collections import defaultdict\n",
    "gender_count = defaultdict(int)\n",
    "for doc in docs:\n",
    "    gender = doc['gender']\n",
    "    gender_count[gender] += 1\n",
    "print(gender_count)\n",
    "\n",
    "# Keys: dict_keys(['rawtext', 'author', 'gender', 'age', 'work', 'tokens', 'actage', 'split', 'attrib'])\n",
    "# Count: 'male': 9812, 'female': 9865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = [\" \".join(doc['tokens']) for doc in docs]\n",
    "gender_label = [int(doc['gender'] == 'male') for doc in docs] # Male 1, Female 0\n",
    "raw_text = [doc['rawtext'] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class GenderDataset(data.Dataset):\n",
    "    def __init__(self, tokenized_docs, label, raw_text = None) -> None:\n",
    "        super().__init__()\n",
    "        tokenized_data = \" \".join([doc for doc in tokenized_docs])\n",
    "        unique_tokens = set(tokenized_data.split())\n",
    "        if raw_text is not None:\n",
    "            self.raw_text = raw_text\n",
    "        self.token2idx = {token: idx for idx, token in enumerate(unique_tokens)}\n",
    "        self.idx2token = {idx: token for idx, token in enumerate(unique_tokens)}\n",
    "        idx_data = [[self.token2idx[token] for token in doc.split()] for doc in tokenized_docs]\n",
    "        self.data = idx_data\n",
    "        self.label = label\n",
    "        self.START_IDX = self.token2idx[\"START\"]\n",
    "        self.END_IDX = self.token2idx[\"END\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "\n",
    "gender_data = GenderDataset(tokenized_docs, gender_label, raw_text=raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([149218,\n",
       "  265216,\n",
       "  172956,\n",
       "  36945,\n",
       "  167485,\n",
       "  149218,\n",
       "  228654,\n",
       "  165716,\n",
       "  36945,\n",
       "  167485,\n",
       "  149218,\n",
       "  239613,\n",
       "  200533,\n",
       "  196815,\n",
       "  36945,\n",
       "  167485,\n",
       "  149218,\n",
       "  141124,\n",
       "  128864,\n",
       "  60142,\n",
       "  21862,\n",
       "  36945,\n",
       "  167485,\n",
       "  149218,\n",
       "  120144,\n",
       "  167857,\n",
       "  171059,\n",
       "  214726,\n",
       "  167485,\n",
       "  149218,\n",
       "  61457,\n",
       "  2395,\n",
       "  162476,\n",
       "  42881,\n",
       "  5007,\n",
       "  96810,\n",
       "  229573,\n",
       "  278627,\n",
       "  1074,\n",
       "  2395,\n",
       "  61457,\n",
       "  2395,\n",
       "  132820,\n",
       "  2395,\n",
       "  68341,\n",
       "  37311,\n",
       "  200533,\n",
       "  84916,\n",
       "  2395,\n",
       "  180859,\n",
       "  170738,\n",
       "  200533,\n",
       "  188333,\n",
       "  252418,\n",
       "  36945,\n",
       "  167485,\n",
       "  149218,\n",
       "  278817,\n",
       "  104143,\n",
       "  171059,\n",
       "  90770,\n",
       "  33541,\n",
       "  36945,\n",
       "  167485],\n",
       " 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
